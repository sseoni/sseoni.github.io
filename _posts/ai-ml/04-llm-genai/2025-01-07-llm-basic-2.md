---
layout: post

title: "LLM Engineering 2. LLM에 지식 주입하기"
date: 2025-05-05
tags: [스터디로그, NLP, LLM, Agent, LLM_Architecture, RAG, Langchain]
summary:
---

이전 포스트에서 LLM은 **"똑똑하지만 기억력이 없는 연산 장치"**라고 정의했다.

그러면 LLM에 지식을 넣어줘야하는데 지식을 넣는 방법은 크게 4가지가 있다.


### 1. 사전 학습 (Pre-training)

> 비유: 초·중·고·대학교 정규 교육 과정
> 
- **설명:** 모델이 태어나는 단계이다. 인터넷상의 방대한 데이터(위키피디아, 책, 뉴스 등)를 읽고 **언어의 문법, 일반 상식, 논리력**을 배운다.
- **특징:**
    - 비용이 천문학적입니다 (수십억~수천억 원).
    - 한번 학습이 끝나면 지식이 고정됩니다 (Knowledge Cutoff). 예: 2023년까지 데이터로 학습한 모델은 2024년 올림픽 결과를 모른다.
- **목적:** "말을 할 줄 아는" 똑똑한 뇌를 만드는 과정.

### 2. 파인 튜닝 (Fine-tuning)

> 비유: 입사 후 받는 직무 전문 연수 (OJT)
> 
- **설명:** 이미 똑똑한 모델(Pre-trained Model)에 **특정 분야의 데이터(법률, 의학, 코딩 등)를 추가로 학습**시켜 전문성을 높이는 과정이다.
- **특징:**
    - **지식 주입보다는 '형식'과 '말투'를 배우는 데 더 효과적**이다. (예: 의사처럼 말하기, SQL 쿼리만 뱉어내기)
    - 새로운 사실(Fact)을 주입하려고 하면 잘 안되거나 환각(Hallucination)이 생길 수 있다.
- **목적:** 범용 모델을 "특수 목적 전문가"로 튜닝하는 과정.

### 3. 강화 학습 (RLHF: Reinforcement Learning from Human Feedback)

> 비유: 예절 교육 및 사회화 (도덕 선생님의 교정)
> 
- **설명:** 모델이 내놓은 답변에 대해 인간이 점수를 매겨("이건 좋은 답변이야", "이건 나쁜 답변이야") 모델의 **행동 양식을 교정**하는 것이다.
- **특징:**
    - 새로운 지식을 배우는 게 아니라, **"사람이 선호하는 방식"**으로 말하도록 훈련한다.
    - 욕설, 편향, 위험한 답변을 막는 안전장치 역할을 한다.
- **목적:** 똑똑한 모델을 "안전하고 도움이 되는" 모델로 만드는 과정.

### 4. RAG (Retrieval-Augmented Generation)

> 비유: 업무 중 매뉴얼이나 검색 엔진 펴놓고 일하기 (Open Book)
> 
- **설명:** 모델을 재학습시키지 않고, 질문이 들어올 때마다 **외부 데이터베이스(Vector DB 등)에서 필요한 정보를 찾아(Retrieve)** 보여주는 방식이다.
- **특징:**
    - **최신 정보**와 **비공개 정보(사내 문서)**를 다루는 데 가장 적합하다.
    - 학습 비용이 들지 않고, 데이터만 갈아끼우면 되므로 업데이트가 쉽다.
    - 출처를 명확히 댈 수 있어 신뢰도가 높다.
- **목적:** 모델의 부족한 지식을 실시간으로 보완하는 과정.

---

### 한눈에 비교하기 (요약표)

| 구분 | 방법 | 비유 | 핵심 역할 | 비용/난이도 |
| --- | --- | --- | --- | --- |
| **학습** | **Pre-training** | 정규 교육 | 언어 능력 & 일반 상식 탑재 | 최상 (불가능에 가까움) |
| **학습** | **Fine-tuning** | 직무 연수 | 특정 도메인 말투/형식 적응 | 중~상 |
| **학습** | **RLHF** | 예절 교육 | 안전성 & 답변 품질 교정 | 상 |
| **추론** | **RAG** | **오픈북 시험** | **최신/사내 정보 실시간 참조** | **하~중 (가성비 최고)** |

### 결론: 우리는 무엇을 해야 할까?

대부분의 LLM 애플리케이션 개발자에게 필요한 전략은 다음과 같다.

1. **똑똑한 모델을 가져온다:** (OpenAI, Anthropic 등의 **Pre-trained Model** 활용)
2. **지식을 연결한다:** (우리의 데이터를 **RAG**로 연결)
3. **그래도 안 되면 튜닝한다:** (RAG로도 말투나 형식이 교정 안 될 때 **Fine-tuning** 고려)